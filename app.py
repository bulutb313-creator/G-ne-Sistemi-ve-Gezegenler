import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import Chroma 
from langchain.docstore.document import Document
import pdfplumber
from langchain.text_splitter import RecursiveCharacterTextSplitter


# --- RAG ZÄ°NCÄ°RÄ°NÄ° BAÅLATAN FONKSÄ°YON ---
@st.cache_resource
def get_rag_chain():
    """TÃ¼m RAG sistemini kurar ve zinciri dÃ¶ndÃ¼rÃ¼r."""
    
    # 1. ManÃ¼el Metin ParÃ§alarÄ± (Test iÃ§in kÄ±sÄ±tlÄ± set)
    texts = [
        Document(page_content="GÃ¼neÅŸ sistemindeki en sÄ±cak gezegen: VenÃ¼s", metadata={"source": "sistem.pdf"}),
        Document(page_content="GÃ¼neÅŸ sistemindeki en soÄŸuk gezegen: UranÃ¼s", metadata={"source": "sistem.pdf"}),
        Document(page_content="Yer kabuÄŸu ile manto arasÄ±ndaki sÄ±nÄ±ra Mohorovicic SÃ¼reksizliÄŸi (Moho) denilir.", metadata={"source": "sistem.pdf"}),
        Document(page_content="JÃ¼piter, GÃ¼neÅŸ sisteminin en bÃ¼yÃ¼k gezegenidir ve 63 uyduya sahiptir.", metadata={"source": "sistem.pdf"}),
        Document(page_content="Mantonun kalÄ±nlÄ±ÄŸÄ± en az 700 km, en fazla 2900 km civarÄ±ndadÄ±r ve DÃ¼nya'nÄ±n toplam hacminin %84'Ã¼nÃ¼ oluÅŸturur. DÃ¼nya'nÄ±n en bÃ¼yÃ¼k katmanÄ±dÄ±r.", metadata={"source": "sistem.pdf"}),
    ]
    
    # 2. Embedding Modeli ve VektÃ¶r VeritabanÄ± OluÅŸturma
    embedding_model = GoogleGenerativeAIEmbeddings(model="text-embedding-004") 
    
    try:
        vectorstore = Chroma.from_documents(documents=texts, embedding=embedding_model)
    except Exception as e:
        st.error(f"VektÃ¶r veritabanÄ± kurulamadÄ±: {e}")
        return None

    # 3. LLM, Retriever ve Prompt
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 8}) 

    prompt_template = """Sen bir GÃœNEÅ SÄ°STEMÄ° VE GEZEGENLER CHATBOTU'sun. GÃ¶revin, sana verilen BAÄLAMI (GÃœNEÅ SÄ°STEMÄ° VE GEZEGENLER HAKKINDAKÄ° BELGEYÄ°) kullanarak kullanÄ±cÄ± sorularÄ±nÄ± AKICI ve MÃœMKÃœN OLDUÄUNCA detaylÄ±ca cevaplamaktÄ±r. CevabÄ±nÄ± doÄŸal ve aÃ§Ä±klayÄ±cÄ± yap.

EÄŸer cevap BAÄLAM'da yoksa, sadece "Bu konuda elimde yeterli bilgi yok." diye cevap ver. Asla uydurma bilgi verme.

BAÄLAM: {context}

Soru: {question}
Cevap:"""

    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT} 
    )
    return qa_chain


# --- STREAMLIT ARAYÃœZÃœ ANA FONKSÄ°YONU ---

def main():
    # BaÅŸlÄ±k ve Emojiler Eklendi
    st.title("ğŸš€ GÃœNEÅ SÄ°STEMÄ° VE GEZEGENLER RAG Chatbot ğŸª")
    st.caption("Akbank GenAI Bootcamp Projesi. Cevaplar sadece 'sistem.pdf'ten alÄ±nmÄ±ÅŸtÄ±r. ğŸ›°ï¸")
    st.write("ğŸŒ Bu chatbot, gezegenler ve yerkÃ¼renin yapÄ±sÄ± hakkÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlar.")


    # API AnahtarÄ±nÄ± al ve kontrol et (os.environ'dan kontrol eder)
    if "GEMINI_API_KEY" not in os.environ:
        st.error("LÃ¼tfen Gemini API AnahtarÄ±nÄ±zÄ± giriniz. Anahtar olmadan sistem Ã§alÄ±ÅŸmaz.")
        key = st.text_input("API AnahtarÄ±:", type="password")
        if key:
            os.environ["GEMINI_API_KEY"] = key
            st.session_state["api_set"] = True
            st.rerun()
        return
    
    # RAG Zincirini YÃ¼kle
    if "qa_chain" not in st.session_state:
        st.session_state.qa_chain = get_rag_chain()
        if st.session_state.qa_chain is None:
            return

    # Sohbet GeÃ§miÅŸi
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # KullanÄ±cÄ± GiriÅŸi
    if prompt := st.chat_input("GÃ¼neÅŸ Sistemi hakkÄ±nda bir soru sorun..."):
        
        # KullanÄ±cÄ± mesajÄ±nÄ± kaydet
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Chatbot'tan cevap al
        with st.chat_message("assistant"):
            with st.spinner("Cevap aranÄ±yor... ğŸŒ‘... ğŸª... â˜„ï¸"):
                try:
                    # RAG zincirini Ã§alÄ±ÅŸtÄ±r
                    answer = st.session_state.qa_chain.run(prompt)
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                except Exception as e:
                    st.error(f"API hatasÄ± oluÅŸtu. LÃ¼tfen anahtarÄ±nÄ±zÄ± kontrol edin: {e}")

if __name__ == "__main__":
    main()
