import streamlit as st
import os
import pdfplumber 

# --- KESÄ°NLÄ°KLE SON HATA GÄ°DERÄ°LMÄ°Åž KÃœTÃœPHANE YOLLARI ---
# Core, Community ve yeni yollar kullanÄ±ldÄ±.
from langchain_core.prompts import PromptTemplate 
from langchain_core.documents import Document 
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma 
from langchain_community.retrievers import MultiQueryRetriever 
from langchain_community.chains import RetrievalQA # <-- SON VE KESÄ°N DÃœZELTME: Chains paketi Community iÃ§ine taÅŸÄ±nmÄ±ÅŸtÄ±r.


# --- RAG ZÄ°NCÄ°RÄ°NÄ° BAÅžLATAN FONKSÄ°YON ---
@st.cache_resource
def get_rag_chain():
    """RAG sistemini kurar ve zinciri dÃ¶ndÃ¼rÃ¼r."""
    PDF_DOSYA_ADI = "sistem.pdf"
    file_path = PDF_DOSYA_ADI

    if not os.path.exists(file_path):
        st.error(f"KRÄ°TÄ°K HATA: '{file_path}' dosyasÄ± GitHub'da bulunamÄ±yor.")
        return None
    try:
        # 1. VERÄ° Ä°ÅžLEME
        full_text = "";
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages: full_text += page.extract_text() + "\n\n"
        documents = [Document(page_content=full_text, metadata={"source": file_path})]
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, overlap=200, separators=["\n\n", "\n", " ", ""],)
        texts = text_splitter.split_documents(documents)

        # 2. VektÃ¶r VeritabanÄ± OluÅŸturma
        embedding_model = GoogleGenerativeAIEmbeddings(model="text-embedding-004")
        vectorstore = Chroma.from_documents(documents=texts, embedding=embedding_model)

        # 3. RAG Zinciri Kurulumu
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2)
        base_retriever = vectorstore.as_retriever(search_kwargs={"k": 8})
        # MultiQueryRetriever kullanÄ±mÄ±
        retriever = MultiQueryRetriever.from_llm(retriever=base_retriever, llm=llm)

        # ANALÄ°TÄ°K PROMPT ÅžABLONU
        prompt_template = """Sen bir GÃœNEÅž SÄ°STEMÄ° VE JEOFIZIK UZMANISIN. GÃ¶revin, sana verilen BAÄžLAM'daki bilgileri ANALÄ°Z EDEREK bir cevap SENTEZLEMEKTÄ°R. Neden-sonuÃ§ iliÅŸkileri kur, kÄ±yaslamalar yap ve mantÄ±ksal Ã§Ä±karÄ±mlar sun.

        EÄŸer cevap KESÄ°NLÄ°KLE BAÄžLAM'da yoksa, sadece "Bu konuda elimde yeterli bilgi yok." diye cevap ver.
        BAÄžLAM: {context}
        Soru: {question}
        Cevap:"""
        PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

        qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever, chain_type_kwargs={"prompt": PROMPT})
        return qa_chain

    except Exception as e:
        st.error(f"RAG Zinciri KurulamadÄ±. LÃ¼tfen API AnahtarÄ±nÄ±zÄ± ve GitHub dosyalarÄ±nÄ±zÄ± kontrol edin. Hata: {e}")
        return None

# --- STREAMLIT ARAYÃœZÃœ ANA FONKSÄ°YONU ---
def main():
    st.set_page_config(page_title="Analitik Chatbot", layout="wide")
    st.title("ðŸš€ GÃœNEÅž SÄ°STEMÄ° VE GEZEGENLER RAG Chatbot (Analitik Uzman) ðŸª")
    st.caption("Cevaplar 'sistem.pdf' dosyasÄ±ndaki TÃœM bilgilerden analitik sentezlenmiÅŸtir. Streamlit Cloud'da kalÄ±cÄ± yayÄ±nda. ðŸ›°ï¸")

    # API AnahtarÄ±nÄ± al ve kontrol et (Secrets'Ä± okur)
    if "GEMINI_API_KEY" not in os.environ:
        st.error("LÃ¼tfen Gemini API AnahtarÄ±nÄ±zÄ± giriniz. Anahtar olmadan sistem Ã§alÄ±ÅŸmaz.")
        key = st.text_input("Gemini API AnahtarÄ±:", type="password", key="api_input") 
        if key:
            os.environ["GEMINI_API_KEY"] = key
            st.rerun()
        return

    # Chain'i baÅŸlat
    if "qa_chain" not in st.session_state:
        st.session_state.qa_chain = get_rag_chain()
        if st.session_state.qa_chain is None: return

    if "messages" not in st.session_state: st.session_state.messages = []
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])

    if prompt := st.chat_input("GÃ¼neÅŸ Sistemi hakkÄ±nda analitik bir soru sorun..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Analiz ediliyor... Neden-sonuÃ§ iliÅŸkileri kuruluyor... ðŸ§ "):
                try:
                    answer = st.session_state.qa_chain.run(prompt)
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                except Exception as e:
                    st.error(f"API hatasÄ± oluÅŸtu veya zincir Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±. Hata: {e}")

if __name__ == "__main__":
    main()
