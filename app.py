import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import Chroma 
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.retrievers.multi_query import MultiQueryRetriever

# --- RAG ZÄ°NCÄ°RÄ°NÄ° BAÅLATAN FONKSÄ°YON (Sadece 1 kere Ã§alÄ±ÅŸÄ±r!) ---
# @st.cache_resource, RAG bileÅŸenlerinin Streamlit'in hafÄ±zasÄ±nda kalmasÄ±nÄ± garanti eder.
@st.cache_resource
def get_rag_chain():
    """TÃ¼m RAG sistemini kurar ve zinciri dÃ¶ndÃ¼rÃ¼r."""
    
    # 1. Metin ParÃ§alarÄ± (Final Ã–ÄŸretisi)
    # Bu, chatbot'un spresifik ve hassas bilgileri Ã¶ÄŸrendiÄŸi garantili verilerdir.
    texts = [
        Document(page_content="GÃ¼neÅŸe en yakÄ±n gezegen MerkÃ¼r'dÃ¼r. MerkÃ¼r, gÃ¼neÅŸe en yakÄ±n ve gÃ¼neÅŸ sisteminin en kÃ¼Ã§Ã¼k gezegenidir.", metadata={"source": "TanÄ±m Ã–ÄŸretisi"}),
        Document(page_content="GÃ¼neÅŸe en uzak gezegen NeptÃ¼n'dÃ¼r. NeptÃ¼n, bÃ¼yÃ¼klÃ¼k bakÄ±mÄ±ndan dÃ¶rdÃ¼ncÃ¼ sÄ±rada olan ve teleskopla keÅŸfedilmeden Ã¶nce matematiksel olarak keÅŸfedilmiÅŸ bir gezegendir.", metadata={"source": "TanÄ±m Ã–ÄŸretisi"}),
        Document(page_content="Yer kabuÄŸu ile manto arasÄ±ndaki sÄ±nÄ±r Mohorovicic SÃ¼reksizliÄŸi (Moho) olarak adlandÄ±rÄ±lÄ±r.", metadata={"source": "TanÄ±m Ã–ÄŸretisi"}),
        Document(page_content="GÃ¼neÅŸ sistemindeki gezegenlerin bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe doÄŸru sÄ±ralamasÄ±: JÃ¼piter, SatÃ¼rn, UranÃ¼s, NeptÃ¼n, DÃ¼nya, VenÃ¼s, Mars, MerkÃ¼r.", metadata={"source": "TanÄ±m Ã–ÄŸretisi"}),
        Document(page_content="Mantonun kalÄ±nlÄ±ÄŸÄ± en az 700 km, en fazla 2900 km civarÄ±ndadÄ±r ve DÃ¼nya'nÄ±n toplam hacminin %84'Ã¼nÃ¼ oluÅŸturur. DÃ¼nya'nÄ±n en bÃ¼yÃ¼k katmanÄ±dÄ±r.", metadata={"source": "TanÄ±m Ã–ÄŸretisi"}),
        Document(page_content="Atmosferin temel katmanlarÄ± (alÃ§aktan yÃ¼kseÄŸe): Troposfer, Stratosfer, Mezosfer, Termosfer, Ekzosfer.", metadata={"source": "TanÄ±m Ã–ÄŸretisi"}),
    ]
    
    # 2. Embedding Modeli ve VektÃ¶r VeritabanÄ± OluÅŸturma
    embedding_model = GoogleGenerativeAIEmbeddings(model="text-embedding-004") 
    
    try:
        vectorstore = Chroma.from_documents(documents=texts, embedding=embedding_model)
    except Exception as e:
        st.error(f"VektÃ¶r veritabanÄ± kurulamadÄ±: {e}")
        return None

    # 3. LLM, Retriever ve Prompt (En AkÄ±llÄ± Ayarlar)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2)
    
    # Zeki arama: MultiQuery Retriever ile k=8 parÃ§a Ã§ekiliyor
    base_retriever = vectorstore.as_retriever(search_kwargs={"k": 8})
    retriever = MultiQueryRetriever.from_llm(retriever=base_retriever, llm=llm)

    prompt_template = """Sen bir GÃœNEÅ SÄ°STEMÄ° VE JEOFIZIK UZMANISIN. Sana verilen BAÄLAM'daki tÃ¼m bilgileri kullanarak bir cevap SENTEZLE. CevabÄ±nÄ± MUTLAKA BAÄLAM'daki bilgilere dayandÄ±rarak oluÅŸtur. CevabÄ±nÄ± AKICI, LÄ°STELER KULLANARAK ve EN KAPSAMLI ÅEKÄ°LDE DETAYLI yap. EÄŸer baÄŸlam yoksa, sadece 'Bu konuda elimde yeterli bilgi yok.' de.
        BAÄLAM: {context}
        Soru: {question}
        Cevap:"""
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT} 
    )
    return qa_chain


# --- STREAMLIT ARAYÃœZÃœ ANA FONKSÄ°YONU ---

def main():
    st.title("ğŸš€ GÃœNEÅ SÄ°STEMÄ° VE GEZEGENLER RAG Chatbot ğŸª")
    st.caption("Cevaplar sadece 'sistem.pdf'ten alÄ±nmÄ±ÅŸtÄ±r. ğŸ›°ï¸")

    # API AnahtarÄ±nÄ± al ve kontrol et
    if "GEMINI_API_KEY" not in os.environ:
        st.error("LÃ¼tfen Gemini API AnahtarÄ±nÄ±zÄ± giriniz. Anahtar olmadan sistem Ã§alÄ±ÅŸmaz.")
        key = st.text_input("API AnahtarÄ±:", type="password")
        if key:
            os.environ["GEMINI_API_KEY"] = key
            st.rerun() # Anahtar yÃ¼klendikten sonra yeniden baÅŸlat
        return
    
    # RAG Zincirini YÃœKLE (Cache sayesinde hÄ±zlÄ±ca yÃ¼klenir)
    if "qa_chain" not in st.session_state:
        st.session_state.qa_chain = get_rag_chain()
        if st.session_state.qa_chain is None:
            return

    # Sohbet GeÃ§miÅŸi
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # KullanÄ±cÄ± GiriÅŸi
    if prompt := st.chat_input("GÃ¼neÅŸ Sistemi hakkÄ±nda bir soru sorun..."):
        
        # KullanÄ±cÄ± mesajÄ±nÄ± kaydet
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Chatbot'tan cevap al
        with st.chat_message("assistant"):
            with st.spinner("Cevap aranÄ±yor... ğŸŒ‘... ğŸª... â˜„ï¸"):
                try:
                    # RAG zincirini Ã§alÄ±ÅŸtÄ±r
                    answer = st.session_state.qa_chain.run(prompt)
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                except Exception as e:
                    st.error(f"API hatasÄ± oluÅŸtu veya zincir kurulamadÄ±. LÃ¼tfen API anahtarÄ±nÄ± kontrol edin: {e}")

if __name__ == "__main__":
    main()
